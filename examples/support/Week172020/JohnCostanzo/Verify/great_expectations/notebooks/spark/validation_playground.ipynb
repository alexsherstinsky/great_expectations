{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Playground\n",
    "\n",
    "**Watch** a [short tutorial video](https://greatexpectations.io/videos/getting_started/integrate_expectations) or **read** [the written tutorial](https://docs.greatexpectations.io/en/latest/tutorials/validate_data.html?utm_source=notebook&utm_medium=validate_data)\n",
    "\n",
    "#### This notebook assumes that you created at least one expectation suite in your project.\n",
    "#### Here you will learn how to validate data loaded into a PySpark DataFrame against an expectation suite.\n",
    "\n",
    "\n",
    "We'd love it if you **reach out for help on** the [**Great Expectations Slack Channel**](https://greatexpectations.io/slack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-21T16:42:33-0700 - INFO - Great Expectations logging enabled at 20 level by JupyterUX module.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import great_expectations as ge\n",
    "import great_expectations.jupyter_ux\n",
    "from great_expectations.datasource.types import BatchKwargs\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get a DataContext\n",
    "This represents your **project** that you just created using `great_expectations init`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ge.data_context.DataContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choose an Expectation Suite\n",
    "\n",
    "List expectation suites that you created in your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Titanic_Test_Alex_0_ExpectationSuite']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.list_expectation_suite_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectation_suite_name = 'Titanic_Test_Alex_0_ExpectationSuite' # TODO: set to a name from the list above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load a batch of data you want to validate\n",
    "\n",
    "To learn more about `get_batch`, see [this tutorial](https://docs.greatexpectations.io/en/latest/tutorials/validate_data.html?utm_source=notebook&utm_medium=validate_data#load-a-batch-of-data-to-validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['leo_datasource']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list datasources of the type SparkDFDatasource in your project\n",
    "[datasource['name'] for datasource in context.list_datasources() if datasource['class_name'] == 'SparkDFDatasource']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource_name = 'leo_datasource' # TODO: set to a datasource name from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you would like to validate a file on a filesystem:\n",
    "# batch_kwargs = {'path': \"YOUR_FILE_PATH\", 'datasource': datasource_name}\n",
    "# # To customize how Spark reads the file, you can add options under reader_options key in batch_kwargs (e.g., header='true') \n",
    "\n",
    "# # If you already loaded the data into a PySpark Data Frame:\n",
    "# batch_kwargs = {'dataset': \"YOUR_DATAFRAME\", 'datasource': datasource_name}\n",
    "\n",
    "\n",
    "# batch = context.get_batch(batch_kwargs, expectation_suite_name)\n",
    "# batch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/alexsherstinsky/Downloads/GESupport04202020/JohnCostanzo/Verify/Titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_kwargs = {'path': path, 'datasource': datasource_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-21T17:03:20-0700 - INFO - \t8 expectation(s) included in expectation_suite.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>_c1</th>\n",
       "      <th>_c2</th>\n",
       "      <th>_c3</th>\n",
       "      <th>_c4</th>\n",
       "      <th>_c5</th>\n",
       "      <th>_c6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Name</td>\n",
       "      <td>PClass</td>\n",
       "      <td>Age</td>\n",
       "      <td>Sex</td>\n",
       "      <td>Survived</td>\n",
       "      <td>SexCode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _c0                                            _c1     _c2  _c3     _c4  \\\n",
       "0  None                                           Name  PClass  Age     Sex   \n",
       "1     1                   Allen, Miss Elisabeth Walton     1st   29  female   \n",
       "2     2                    Allison, Miss Helen Loraine     1st    2  female   \n",
       "3     3            Allison, Mr Hudson Joshua Creighton     1st   30    male   \n",
       "4     4  Allison, Mrs Hudson JC (Bessie Waldo Daniels)     1st   25  female   \n",
       "\n",
       "        _c5      _c6  \n",
       "0  Survived  SexCode  \n",
       "1         1        1  \n",
       "2         0        1  \n",
       "3         0        0  \n",
       "4         0        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = context.get_batch(batch_kwargs, expectation_suite_name)\n",
    "batch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from pyspark import SQLContext\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.get('PYSPARK_PYTHON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session = SparkSession.builder.appName(\"pytest-pyspark-local-notebook-manage_expectations\"). \\\n",
    "    master(\"local[2]\"). \\\n",
    "    config(\"spark.executor.memory\", \"6g\"). \\\n",
    "    config(\"spark.driver.memory\", \"6g\"). \\\n",
    "    config(\"spark.ui.showConsoleProgress\", \"false\"). \\\n",
    "    config(\"spark.sql.shuffle.partitions\", \"2\"). \\\n",
    "    config(\"spark.default.parallelism\", \"4\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    getOrCreate()\n",
    "sc = spark_session.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------------------------+------+----+------+--------+-------+\n",
      "|_c0|Name                                            |PClass|Age |Sex   |Survived|SexCode|\n",
      "+---+------------------------------------------------+------+----+------+--------+-------+\n",
      "|1  |Allen, Miss Elisabeth Walton                    |1st   |29  |female|1       |1      |\n",
      "|2  |Allison, Miss Helen Loraine                     |1st   |2   |female|0       |1      |\n",
      "|3  |Allison, Mr Hudson Joshua Creighton             |1st   |30  |male  |0       |0      |\n",
      "|4  |Allison, Mrs Hudson JC (Bessie Waldo Daniels)   |1st   |25  |female|0       |1      |\n",
      "|5  |Allison, Master Hudson Trevor                   |1st   |0.92|male  |1       |0      |\n",
      "|6  |Anderson, Mr Harry                              |1st   |47  |male  |1       |0      |\n",
      "|7  |Andrews, Miss Kornelia Theodosia                |1st   |63  |female|1       |1      |\n",
      "|8  |Andrews, Mr Thomas, jr                          |1st   |39  |male  |0       |0      |\n",
      "|9  |Appleton, Mrs Edward Dale (Charlotte Lamson)    |1st   |58  |female|1       |1      |\n",
      "|10 |Artagaveytia, Mr Ramon                          |1st   |71  |male  |0       |0      |\n",
      "|11 |Astor, Colonel John Jacob                       |1st   |47  |male  |0       |0      |\n",
      "|12 |Astor, Mrs John Jacob (Madeleine Talmadge Force)|1st   |19  |female|1       |1      |\n",
      "|13 |Aubert, Mrs Leontine Pauline                    |1st   |NA  |female|1       |1      |\n",
      "|14 |Barkworth, Mr Algernon H                        |1st   |NA  |male  |1       |0      |\n",
      "|15 |Baumann, Mr John D                              |1st   |NA  |male  |0       |0      |\n",
      "|16 |Baxter, Mrs James (Helene DeLaudeniere Chaput)  |1st   |50  |female|1       |1      |\n",
      "|17 |Baxter, Mr Quigg Edmond                         |1st   |24  |male  |0       |0      |\n",
      "|18 |Beattie, Mr Thomson                             |1st   |36  |male  |0       |0      |\n",
      "|19 |Beckwith, Mr Richard Leonard                    |1st   |37  |male  |1       |0      |\n",
      "|20 |Beckwith, Mrs Richard Leonard (Sallie Monypeny) |1st   |47  |female|1       |1      |\n",
      "+---+------------------------------------------------+------+----+------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_kwargs = {'dataset': df, 'datasource': datasource_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-21T17:16:24-0700 - INFO - \t8 expectation(s) included in expectation_suite.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>1st</td>\n",
       "      <td>0.92</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                           Name PClass   Age     Sex  \\\n",
       "0   1                   Allen, Miss Elisabeth Walton    1st    29  female   \n",
       "1   2                    Allison, Miss Helen Loraine    1st     2  female   \n",
       "2   3            Allison, Mr Hudson Joshua Creighton    1st    30    male   \n",
       "3   4  Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st    25  female   \n",
       "4   5                  Allison, Master Hudson Trevor    1st  0.92    male   \n",
       "\n",
       "  Survived SexCode  \n",
       "0        1       1  \n",
       "1        0       1  \n",
       "2        0       0  \n",
       "3        0       1  \n",
       "4        1       0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = context.get_batch(batch_kwargs, expectation_suite_name)\n",
    "batch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-21T17:21:08-0700 - INFO - Profiling 'leo_datasource' with 'BasicDatasetProfiler'\n",
      "2020-04-21T17:21:08-0700 - INFO -             Preparing column 1 of 7: _c0\n",
      "2020-04-21T17:21:08-0700 - INFO -             Preparing column 2 of 7: Name\n",
      "2020-04-21T17:21:08-0700 - INFO -             Preparing column 3 of 7: PClass\n",
      "2020-04-21T17:21:08-0700 - INFO -             Preparing column 4 of 7: Age\n",
      "2020-04-21T17:21:09-0700 - INFO -             Preparing column 5 of 7: Sex\n",
      "2020-04-21T17:21:09-0700 - INFO -             Preparing column 6 of 7: Survived\n",
      "2020-04-21T17:21:09-0700 - INFO -             Preparing column 7 of 7: SexCode\n",
      "2020-04-21T17:21:09-0700 - INFO - \t49 expectation(s) included in expectation_suite.\n",
      "2020-04-21T17:21:11-0700 - INFO - \tProfiled 7 columns using 1313 rows from None (2.634 sec)\n",
      "2020-04-21T17:21:11-0700 - INFO - \n",
      "Profiled the data asset, with 1313 total rows and 7 columns in 2.64 seconds.\n",
      "Generated, evaluated, and stored 49 Expectations during profiling. Please review results using data-docs.\n",
      "Profiling completed\n"
     ]
    }
   ],
   "source": [
    "profile_results = context.profile_data_asset(\n",
    "    datasource_name=\"leo_datasource\",\n",
    "    expectation_suite_name=expectation_suite_name,\n",
    "    batch_kwargs=batch_kwargs,\n",
    ")\n",
    "\n",
    "if profile_results[\"success\"]:\n",
    "    print(\"Profiling completed\")\n",
    "    context.build_data_docs()\n",
    "else:\n",
    "    print(\"Profiling failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.read.parquet(hdfs_file)\n",
    "# df.show(20, False)\n",
    "\n",
    "# context = ge.DataContext()\n",
    "# batch_kwargs = {\n",
    "#     \"datasource\": \"leo_datasource\",\n",
    "#     \"dataset\": df.limit(1000),\n",
    "# }\n",
    "\n",
    "# # profile the dataset and create or overwrite the given expectation suite name\n",
    "# profile_results = context.profile_data_asset(\n",
    "#     datasource_name=\"leo_datasource\",\n",
    "#     expectation_suite_name=category,\n",
    "#     batch_kwargs=batch_kwargs,\n",
    "# )\n",
    "\n",
    "# if profile_results[\"success\"]:\n",
    "#     logger.info(\"Profiling completed\")\n",
    "#     context.build_data_docs()\n",
    "# else:\n",
    "#     logger.error(\"Profiling failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-21T17:23:02-0700 - INFO - Setting run_id to: 20200422T002302.411112Z\n",
      "2020-04-21T17:23:02-0700 - INFO - \t8 expectation(s) included in expectation_suite.\n",
      "Validations completed\n"
     ]
    }
   ],
   "source": [
    "results = context.run_validation_operator(\n",
    "    \"action_list_operator\", \n",
    "    assets_to_validate=[batch], \n",
    ")\n",
    "\n",
    "if results[\"success\"]:\n",
    "    print(\"Validations completed\")\n",
    "    context.build_data_docs()\n",
    "else:\n",
    "    print(\"Validations failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Alex>The code below was not used (only as an example).</Alex>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validate the batch with Validation Operators\n",
    "\n",
    "`Validation Operators` provide a convenient way to bundle the validation of\n",
    "multiple expectation suites and the actions that should be taken after validation.\n",
    "\n",
    "When deploying Great Expectations in a **real data pipeline, you will typically discover these needs**:\n",
    "\n",
    "* validating a group of batches that are logically related\n",
    "* validating a batch against several expectation suites such as using a tiered pattern like `warning` and `failure`\n",
    "* doing something with the validation results (e.g., saving them for a later review, sending notifications in case of failures, etc.).\n",
    "\n",
    "[Read more about Validation Operators in the tutorial](https://docs.greatexpectations.io/en/latest/tutorials/validate_data.html?utm_source=notebook&utm_medium=validate_data#save-validation-results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of invoking a validation operator that is configured by default in the great_expectations.yml file\n",
    "\n",
    "#Generate a run id, a timestamp, or a meaningful string that will help you refer to validation results. We recommend they be chronologically sortable.\n",
    "# Let's make a simple sortable timestamp. Note this could come from your pipeline runner (e.g., Airflow run id).\n",
    "run_id = datetime.utcnow().isoformat().replace(\":\", \"\") + \"Z\"\n",
    "\n",
    "results = context.run_validation_operator(\n",
    "    \"action_list_operator\", \n",
    "    assets_to_validate=[batch], \n",
    "    run_id=run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. View the Validation Results in Data Docs\n",
    "\n",
    "Let's now build and look at your Data Docs. These will now include an **data quality report** built from the `ValidationResults` you just created that helps you communicate about your data with both machines and humans.\n",
    "\n",
    "[Read more about Data Docs in the tutorial](https://docs.greatexpectations.io/en/latest/tutorials/validate_data.html?utm_source=notebook&utm_medium=validate_data#view-the-validation-results-in-data-docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.open_data_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You ran Validations!\n",
    "\n",
    "## Next steps:\n",
    "\n",
    "### 1. Read about the typical workflow with Great Expectations:\n",
    "\n",
    "[typical workflow](https://docs.greatexpectations.io/en/latest/getting_started/typical_workflow.html?utm_source=notebook&utm_medium=validate_data#view-the-validation-results-in-data-docs)\n",
    "\n",
    "### 2. Explore the documentation & community\n",
    "\n",
    "You are now among the elite data professionals who know how to build robust descriptions of your data and protections for pipelines and machine learning models. Join the [**Great Expectations Slack Channel**](https://greatexpectations.io/slack) to see how others are wielding these superpowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
