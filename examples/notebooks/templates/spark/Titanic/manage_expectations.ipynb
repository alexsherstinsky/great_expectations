{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating & Editing Expectation Suites\n",
    "Use this example notebook as a \"boilerplate\" template for creating and modifying your expectation suites.\n",
    "\n",
    "While the same notebook can be used to manage multiple expectation suites, developers often find it helpful to dedicate a separate notebook for each expectation suite, because it makes the organization of the expectation suites in the code repository more explicit and improves the code readability.\n",
    "\n",
    "## IMPORTANT\n",
    "Be sure to commit your notebook to GitHub as part of your repository!  This notebook is the source of truth, capturing your expectations with respect to the given data asset.  (To facilitate code review, you may wish to \"Restart Kernel and Clear All Outputs\" before committing the notebook to Git).\n",
    "\n",
    "## _We are here to help!_\n",
    "\n",
    "You can always **reach out to us on** the [**Great Expectations Slack Channel**](https://greatexpectations.io/slack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Spark Context and Import Python Basics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from pyspark import SQLContext\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.get('PYSPARK_PYTHON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session = SparkSession.builder.appName(\"pytest-pyspark-local-notebook-manage_expectations\"). \\\n",
    "    master(\"local[2]\"). \\\n",
    "    config(\"spark.executor.memory\", \"6g\"). \\\n",
    "    config(\"spark.driver.memory\", \"6g\"). \\\n",
    "    config(\"spark.ui.showConsoleProgress\", \"false\"). \\\n",
    "    config(\"spark.sql.shuffle.partitions\", \"2\"). \\\n",
    "    config(\"spark.default.parallelism\", \"4\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    getOrCreate()\n",
    "sc = spark_session.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Useful Python Utilities\n",
    "\n",
    "Also import GreatExpectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import great_expectations as ge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Repository Repository to Spark Context\n",
    "\n",
    "Also import frequently used utilities from your repository.\n",
    "\n",
    "### _Important_\n",
    "Make sure that the path to your repository archive in S3 for the `sc.addPyFile(s3_path_to_repo_zip)` call below is correct and that the contents are up to date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.addPyFile('s3://alex-ge-test/code-0.0.0.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(spark_context, path, delimiter):\n",
    "    return spark_context.read \\\n",
    "        .format(\"com.databricks.spark.csv\") \\\n",
    "        .option(\"delimiter\", delimiter) \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .load(path)\n",
    "\n",
    "\n",
    "def load_parquet(spark_context, path, prefix_path=None, select_cols=None):\n",
    "    if prefix_path is None:\n",
    "        spark_parquet_read_func = spark_context.read\n",
    "    else:\n",
    "        spark_parquet_read_func = spark_context.read.option(\"basePath\", prefix_path)\n",
    "\n",
    "    if isinstance(path, list):\n",
    "        df = spark_parquet_read_func.parquet(*path)\n",
    "    else:\n",
    "        df = spark_parquet_read_func.parquet(path)\n",
    "\n",
    "    if select_cols:\n",
    "        df = df.select(*select_cols)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GreatExpectations Basics\n",
    "\n",
    "Check GreatExpections version.\n",
    "\n",
    "Import the GreatExpections `get_ge_context()` method and execute it using the standard buckets as the parameters:\n",
    "* json_s3_bucket -- stores JSON files containing the authoritative expectation suites definitions and validation results\n",
    "* html_docs_s3_bucket -- stores HTML files for displaying the expectation suites definitions and reporting their corresponding validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from repo.lib.test.great_expectations.ge_context import get_ge_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from great_expectations.data_context.types.base import DataContextConfig\n",
    "from great_expectations.data_context import BaseDataContext\n",
    "\n",
    "class GeContext(object):\n",
    "    def __init__(\n",
    "            self,\n",
    "            json_s3_bucket,\n",
    "            html_docs_s3_bucket,\n",
    "            site_name='s3_site',\n",
    "            slack_webhook=None\n",
    "    ):\n",
    "        GeContext._validate_arguments(\n",
    "            json_s3_bucket=json_s3_bucket,\n",
    "            html_docs_s3_bucket=html_docs_s3_bucket,\n",
    "            site_name=site_name,\n",
    "            slack_webhook=slack_webhook\n",
    "        )\n",
    "        self._site_name = site_name\n",
    "        action_list = [\n",
    "            {\n",
    "                'name': 'store_validation_result',\n",
    "                'action': {\n",
    "                    'class_name': 'StoreValidationResultAction'\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'name': 'store_evaluation_params',\n",
    "                'action': {\n",
    "                    'class_name': 'StoreEvaluationParametersAction'\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'name': 'update_data_docs',\n",
    "                'action': {\n",
    "                    'class_name': 'UpdateDataDocsAction'\n",
    "                }\n",
    "            },\n",
    "        ]\n",
    "        \n",
    "        notify_slack_action_dict = {\n",
    "            'name': 'notify_slack',\n",
    "            'action': {\n",
    "                'class_name': 'SlackNotificationAction',\n",
    "                'slack_webhook': slack_webhook,\n",
    "                'notify_on': 'all',\n",
    "                'renderer': {\n",
    "                    'module_name': 'great_expectations.render.renderer.slack_renderer',\n",
    "                    'class_name': 'SlackRenderer'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if slack_webhook is not None:\n",
    "            action_list.append(notify_slack_action_dict)\n",
    "\n",
    "        project_config = DataContextConfig(\n",
    "            config_version=1,\n",
    "            datasources={\n",
    "                's3_files_spark_datasource': {\n",
    "                    'class_name': 'SparkDFDatasource',\n",
    "                    'data_asset_type': {\n",
    "                        'class_name': 'SparkDFDataset'\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            config_variables_file_path=None,\n",
    "            plugins_directory=None,\n",
    "            validation_operators={\n",
    "                'action_list_operator': {\n",
    "                    'class_name': 'ActionListValidationOperator',\n",
    "                    'action_list': action_list\n",
    "                }\n",
    "            },\n",
    "            stores={\n",
    "                'expectations': {\n",
    "                    'class_name': 'ExpectationsStore',\n",
    "                    'store_backend': {\n",
    "                        'class_name': 'TupleS3StoreBackend',\n",
    "                        'bucket': json_s3_bucket,\n",
    "                        'prefix': 'great_expectations/ExpectationSuites'\n",
    "                    }\n",
    "                },\n",
    "                'validations': {\n",
    "                    'class_name': 'ValidationsStore',\n",
    "                    'store_backend': {\n",
    "                        'class_name': 'TupleS3StoreBackend',\n",
    "                        'bucket': json_s3_bucket,\n",
    "                        'prefix': 'great_expectations/Validations'\n",
    "                    }\n",
    "                },\n",
    "                'evaluation_parameters': {\n",
    "                    'class_name': 'EvaluationParameterStore'\n",
    "                }\n",
    "            },\n",
    "            expectations_store_name='expectations',\n",
    "            validations_store_name='validations',\n",
    "            evaluation_parameter_store_name='evaluation_parameters',\n",
    "            data_docs_sites={\n",
    "                self._site_name: {\n",
    "                    'class_name': 'SiteBuilder',\n",
    "                    'store_backend': {\n",
    "                        'class_name': 'TupleS3StoreBackend',\n",
    "                        'bucket': html_docs_s3_bucket,\n",
    "                        'prefix': ''\n",
    "                    },\n",
    "                    'site_index_builder': {\n",
    "                        'class_name': 'DefaultSiteIndexBuilder',\n",
    "                        'show_cta_footer': True\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        ge_context = BaseDataContext(project_config=project_config)\n",
    "        self._ge_context = ge_context\n",
    "\n",
    "    def build_data_docs(self):\n",
    "        self._ge_context.build_data_docs(site_names=self._site_name)\n",
    "\n",
    "    def get_ge_context(self):\n",
    "        return self._ge_context\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate_arguments(json_s3_bucket, html_docs_s3_bucket, site_name, slack_webhook):\n",
    "        if not json_s3_bucket or not isinstance(json_s3_bucket, str):\n",
    "            raise ValueError('Error: \"json_s3_bucket\" must be a non-empty string.')\n",
    "        if not html_docs_s3_bucket or not isinstance(html_docs_s3_bucket, str):\n",
    "            raise ValueError('Error: \"html_docs_s3_bucket\" must be a non-empty string.')\n",
    "        if not site_name or not isinstance(site_name, str):\n",
    "            raise ValueError('Error: \"site_name\" must be a non-empty string.')\n",
    "        if slack_webhook and not isinstance(slack_webhook, str):\n",
    "            raise ValueError('Error: \"slack_webhook\" must be either a non-empty string or entirely omitted.')\n",
    "\n",
    "def get_ge_context(json_s3_bucket, html_docs_s3_bucket, slack_webhook=None):\n",
    "    return GeContext(\n",
    "        json_s3_bucket=json_s3_bucket,\n",
    "        html_docs_s3_bucket=html_docs_s3_bucket,\n",
    "        slack_webhook=slack_webhook\n",
    "    ) \\\n",
    "        .get_ge_context()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_s3_bucket = 'alex-ge-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_docs_s3_bucket = 'alex-ge-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_context = get_ge_context(json_s3_bucket=json_s3_bucket, html_docs_s3_bucket=html_docs_s3_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage Your Expectation Suite\n",
    "Use this notebook to recreate and modify your expectation suite for (write down the name of the expectation suite below for future references):\n",
    "\n",
    "**Expectation Suite Name**: `Titanic_Expectation_Suite`\n",
    "\n",
    "You can always **reach out to us on** the [**Great Expectations Slack Channel**](https://greatexpectations.io/slack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Asset Specification\n",
    "\n",
    "Specify the S3 path to the data asset that you wish to reason about (by characterising it with expectations) in this notebook.  Then use the previously imported utilities to load this asset into a PySpark DataDrame (we also recommend printing some basic information about your dataframe).\n",
    "\n",
    "### Terminology\n",
    "We use the term \"check dataframe\" when referring to the dataframe corresponding to your data asset, because this is the dataframe, on which the various checks against what is expected will be performed in the course of building the expectation suite.  As part of this process, you may need to create additional columns (e.g., to combine existing columns), join different dataframes, and so on in order to produce a check dataframe for expectations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_asset_path = 's3a://alex-ge-test/data_assets/Titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = load_csv(\n",
    "    spark_context=spark,\n",
    "    path=data_asset_path,\n",
    "    delimiter=','\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_check.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df_check.count(), len(df_check.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check.show(n=200, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Expectation Suite Name\n",
    "\n",
    "Now create the name for your expectation suite.\n",
    "\n",
    "We recommend the naming convention that concatenates the root of your outputfile name (or project ID) with the suffix \"_Expectation_Suite\" at the end.  While the name of an expectation suite can be any alphanumeric string, this naming convention facilitates clarity, standardization, and repeatability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectation_suite_name = 'Titanic_Expectation_Suite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Expectation Suite\n",
    "\n",
    "Use the GreatExpectations context to create your expectation suite with the above name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_context.create_expectation_suite(\n",
    "    expectation_suite_name=expectation_suite_name,\n",
    "    overwrite_existing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Data Batch\n",
    "\n",
    "Now wrap your check dataframe into a batch of data within the Great Expectations context.\n",
    "\n",
    "This is a 2-step process.  First, we create keywork arguments as a metadata for your data asset.  Then we use the GreatExpectations context to generate the batch of data from your data asset and place it within the scope of your expectation suite.  We also display several rows of the batch to make sure that the contents are the same as in your original check dataframe.  Finally, we print out the batch keyword arguments for diagnostics purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_kwargs = {\n",
    "    'datasource': 's3_files_spark_datasource',\n",
    "    'dataset': df_check\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ge_context.get_batch(\n",
    "    expectation_suite_name=expectation_suite_name,\n",
    "    batch_kwargs=batch_kwargs\n",
    ")\n",
    "batch.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.batch_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GreatExpectations API\n",
    "\n",
    "The GreatExpectations API provides information about the data batch.  For example, `batch.get_table_columns()` returns the columns of your data asset.  In the remainder of this notebook, you will be expressing your reasoning about the data in these columns by creating various expectations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source_column_names_list = batch.get_table_columns()\n",
    "print(data_source_column_names_list, len(data_source_column_names_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create & Edit Expectations\n",
    "\n",
    "Add expectations by calling specific expectation methods on the `batch` object. They all begin with `.expect_` which makes autocompleting easy using the \"tab\" key.\n",
    "\n",
    "You can see all the available expectations in the **[expectation glossary](https://docs.greatexpectations.io/en/latest/expectation_glossary.html?utm_source=notebook&utm_medium=create_expectations)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = data_source_column_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = batch.expect_table_columns_to_match_ordered_list(\n",
    "    column_list=column_list,\n",
    "    result_format='SUMMARY',\n",
    "    include_config=True,\n",
    "    catch_exceptions=None,\n",
    "    meta=None\n",
    ")\n",
    "print(result, 'Success: {0}'.format(result.success))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = 1300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = batch.expect_table_row_count_to_be_between(\n",
    "    min_value=min_value,\n",
    "    max_value=max_value,\n",
    "    result_format='SUMMARY',\n",
    "    include_config=True,\n",
    "    catch_exceptions=None,\n",
    "    meta=None\n",
    ")\n",
    "print(result, 'Success: {0}'.format(result.success))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Name', 'PClass', 'Age', 'Sex', 'Survived', 'SexCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in column_names:\n",
    "    result = batch.expect_column_values_to_not_be_null(\n",
    "        column=column_name,\n",
    "        mostly=None,\n",
    "        result_format='SUMMARY',\n",
    "        include_config=True,\n",
    "        catch_exceptions=None,\n",
    "        meta=None\n",
    "    )\n",
    "    print(result, 'Success: {0}'.format(result.success))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = '_c0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = batch.expect_column_values_to_not_be_null(\n",
    "    column=column_name,\n",
    "    mostly=9.8e-1,\n",
    "    result_format='SUMMARY',\n",
    "    include_config=True,\n",
    "    catch_exceptions=None,\n",
    "    meta=None\n",
    ")\n",
    "print(result, 'Success: {0}'.format(result.success))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_name = 'Zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex_pattern = '^[0-9]{5}(?:-[0-9]{4})?$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = batch.expect_column_values_to_match_regex(\n",
    "#     column=column_name,\n",
    "#     regex=regex_pattern,\n",
    "#     mostly=9.0e-1,\n",
    "#     result_format='SUMMARY',\n",
    "#     include_config=True,\n",
    "#     catch_exceptions=None,\n",
    "#     meta=None\n",
    "# )\n",
    "# print(result, 'Success: {0}'.format(result.success))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_name = 'Year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_set = [\n",
    "#     2019,\n",
    "#     2020\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = batch.expect_column_values_to_be_in_set(\n",
    "#     column=column_name,\n",
    "#     value_set=value_set,\n",
    "#     mostly=None,\n",
    "#     result_format='SUMMARY',\n",
    "#     include_config=True,\n",
    "#     catch_exceptions=None,\n",
    "#     meta=None\n",
    "# )\n",
    "# print(result, 'Success: {0}'.format(result.success))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_name = 'Week'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_value = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_value = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = batch.expect_column_values_to_be_between(\n",
    "#     column=column_name,\n",
    "#     min_value=min_value,\n",
    "#     max_value=max_value,\n",
    "#     mostly=None,\n",
    "#     result_format='SUMMARY',\n",
    "#     include_config=True,\n",
    "#     catch_exceptions=None,\n",
    "#     meta=None\n",
    "# )\n",
    "# print(result, \"Success: {0}\".format(result.success))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save & Review Your Expectations\n",
    "\n",
    "Let's save the expectation suite as a JSON file in the `great_expectations/expectations` directory of your project.\n",
    "If you decide not to save some expectations that you created, use [remove_expectaton method](https://docs.greatexpectations.io/en/latest/module_docs/data_asset_module.html?highlight=remove_expectation&utm_source=notebook&utm_medium=edit_expectations#great_expectations.data_asset.data_asset.DataAsset.remove_expectation).\n",
    "\n",
    "Let's now rebuild your Data Docs, which helps you communicate about your data with both machines and humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.get_expectation_suite(discard_failed_expectations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.save_expectation_suite(discard_failed_expectations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_context.build_data_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
